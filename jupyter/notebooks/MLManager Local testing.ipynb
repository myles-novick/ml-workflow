{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://splice-releases.s3.amazonaws.com/jdbc-driver/db-client-2.7.0.1815.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "%classpath add jar db-client-2.7.0.1815.jar\n",
    "%defaultDatasource jdbc:splice://host.docker.internal:1527/splicedb;user=splice;password=admin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Initialized\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from splicemachine.spark.context import PySpliceContext\n",
    "import random\n",
    "# Create our Spark Session\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "# Create out Native Database Connection\n",
    "splice = PySpliceContext(spark,JDBC_URL='jdbc:splice://host.docker.internal:1527/splicedb;user=splice;password=admin',_unit_testing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking Model Metadata on MLFlow Server @ http://mlflow:5001\n"
     ]
    }
   ],
   "source": [
    "from splicemachine.ml.management import MLManager\n",
    "manager = MLManager(splice, _testing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment fraud_demo already exists... setting to active experiment\n",
      "Active experiment has id 1\n"
     ]
    }
   ],
   "source": [
    "manager.create_experiment('fraud_demo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Transformer RandomForestClassifier_9c06ce1cad9e could not be parsed. If this is a model, this is expected.\n",
      "Warning: Transformer RandomForestClassifier_9c06ce1cad9e could not be parsed. If this is a model, this is expected.\n",
      "Warning: Transformer MultilayerPerceptronClassifier_6252cda91cbf could not be parsed. If this is a model, this is expected.\n",
      "Warning: Transformer MultilayerPerceptronClassifier_6252cda91cbf could not be parsed. If this is a model, this is expected.\n",
      "Warning: Transformer DecisionTreeClassifier_7d8040305fde could not be parsed. If this is a model, this is expected.\n",
      "Warning: Transformer DecisionTreeClassifier_7d8040305fde could not be parsed. If this is a model, this is expected.\n",
      "Warning: Transformer DecisionTreeRegressor_9c9e614d177c could not be parsed. If this is a model, this is expected.\n",
      "Warning: Transformer DecisionTreeRegressor_9c9e614d177c could not be parsed. If this is a model, this is expected.\n",
      "Warning: Transformer KMeans_898554d51941 could not be parsed. If this is a model, this is expected.\n",
      "Warning: Transformer KMeans_898554d51941 could not be parsed. If this is a model, this is expected.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StandardScaler, VectorAssembler\n",
    "from pyspark.ml import Pipeline,PipelineModel\n",
    "from pyspark.ml.classification import RandomForestClassifier, MultilayerPerceptronClassifier, DecisionTreeClassifier\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "models = [RandomForestClassifier,MultilayerPerceptronClassifier,DecisionTreeClassifier,DecisionTreeRegressor,KMeans]\n",
    "feature_names = ['price','gender','size','name','height','location','age','weather_type','ror']\n",
    "fitted_pipes = []\n",
    "for i in range(5):\n",
    "    #start our first MLFlow run\n",
    "    tags = {\n",
    "            'team': 'splice',\n",
    "            'purpose': 'testing r&d',\n",
    "            'attempt-date': '11/07/2019',\n",
    "            'attempt-number': str(i)\n",
    "           }\n",
    "    manager.start_run(tags=tags)\n",
    "    \n",
    "    # In-place shuffle\n",
    "    random.shuffle(feature_names)\n",
    "\n",
    "    assembler = VectorAssembler(inputCols=feature_names[:5], outputCol='features')\n",
    "    scaler = StandardScaler(inputCol=\"features\", outputCol='scaledFeatures')\n",
    "    model = models[i]()\n",
    "    model = model.setFeaturesCol('scaledFeatures')\n",
    "    \n",
    "    stages = [assembler,scaler,model]\n",
    "    mlpipe = Pipeline(stages=stages)\n",
    "    fitted_pipes.append(mlpipe)\n",
    "    manager.log_pipeline_stages(mlpipe)\n",
    "    \n",
    "    manager.log_feature_transformations(mlpipe)\n",
    "    \n",
    "    manager.log_metric('f1',random.random())\n",
    "    manager.log_metric('acc',random.random())\n",
    "    manager.log_metric('tpr',random.random())\n",
    "    manager.log_metric('fnr',random.random())\n",
    "    manager.log_metric('tnr',random.random())\n",
    "    manager.log_metric('fpr',random.random())\n",
    "    manager.log_metric('precision',random.random())\n",
    "#     manager.log_artifact('MLManager Local testing.ipynb','MLManager Local testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input cols: ['weather_type', 'name', 'height', 'gender', 'location'] output: features\n",
      "col: weather_type\n",
      "first: None\n",
      "defaultdict(<function log_feature_transformations.<locals>.<lambda> at 0x7fdbc204b6a8>, {'weather_type': [['VectorAssembler'], 'features']}) \n",
      "\n",
      "col: name\n",
      "first: None\n",
      "defaultdict(<function log_feature_transformations.<locals>.<lambda> at 0x7fdbc204b6a8>, {'weather_type': [['VectorAssembler'], 'features'], 'name': [['VectorAssembler'], 'features']}) \n",
      "\n",
      "col: height\n",
      "first: None\n",
      "defaultdict(<function log_feature_transformations.<locals>.<lambda> at 0x7fdbc204b6a8>, {'weather_type': [['VectorAssembler'], 'features'], 'name': [['VectorAssembler'], 'features'], 'height': [['VectorAssembler'], 'features']}) \n",
      "\n",
      "col: gender\n",
      "first: None\n",
      "defaultdict(<function log_feature_transformations.<locals>.<lambda> at 0x7fdbc204b6a8>, {'weather_type': [['VectorAssembler'], 'features'], 'name': [['VectorAssembler'], 'features'], 'height': [['VectorAssembler'], 'features'], 'gender': [['VectorAssembler'], 'features']}) \n",
      "\n",
      "col: location\n",
      "first: None\n",
      "defaultdict(<function log_feature_transformations.<locals>.<lambda> at 0x7fdbc204b6a8>, {'weather_type': [['VectorAssembler'], 'features'], 'name': [['VectorAssembler'], 'features'], 'height': [['VectorAssembler'], 'features'], 'gender': [['VectorAssembler'], 'features'], 'location': [['VectorAssembler'], 'features']}) \n",
      "\n",
      "input cols: ['features'] output: scaledFeatures\n",
      "col: features\n",
      "first: ['weather_type', 'name', 'height', 'gender', 'location']\n",
      "Warning: Transformer RandomForestClassifier_9c06ce1cad9e could not be parsed. If this is a model, this is expected.\n",
      "Warning: Transformer RandomForestClassifier_9c06ce1cad9e could not be parsed. If this is a model, this is expected.\n",
      "input cols: None output: None\n",
      "Column- weather_type weather_type -> VectorAssembler -> StandardScaler -> scaledFeatures\n",
      "Column- name name -> VectorAssembler -> StandardScaler -> scaledFeatures\n",
      "Column- height height -> VectorAssembler -> StandardScaler -> scaledFeatures\n",
      "Column- gender gender -> VectorAssembler -> StandardScaler -> scaledFeatures\n",
      "Column- location location -> VectorAssembler -> StandardScaler -> scaledFeatures\n",
      "-------------------------------------------\n",
      "input cols: ['location', 'ror', 'gender', 'name', 'price'] output: features\n",
      "col: location\n",
      "first: None\n",
      "defaultdict(<function log_feature_transformations.<locals>.<lambda> at 0x7fdbc1fb29d8>, {'location': [['VectorAssembler'], 'features']}) \n",
      "\n",
      "col: ror\n",
      "first: None\n",
      "defaultdict(<function log_feature_transformations.<locals>.<lambda> at 0x7fdbc1fb29d8>, {'location': [['VectorAssembler'], 'features'], 'ror': [['VectorAssembler'], 'features']}) \n",
      "\n",
      "col: gender\n",
      "first: None\n",
      "defaultdict(<function log_feature_transformations.<locals>.<lambda> at 0x7fdbc1fb29d8>, {'location': [['VectorAssembler'], 'features'], 'ror': [['VectorAssembler'], 'features'], 'gender': [['VectorAssembler'], 'features']}) \n",
      "\n",
      "col: name\n",
      "first: None\n",
      "defaultdict(<function log_feature_transformations.<locals>.<lambda> at 0x7fdbc1fb29d8>, {'location': [['VectorAssembler'], 'features'], 'ror': [['VectorAssembler'], 'features'], 'gender': [['VectorAssembler'], 'features'], 'name': [['VectorAssembler'], 'features']}) \n",
      "\n",
      "col: price\n",
      "first: None\n",
      "defaultdict(<function log_feature_transformations.<locals>.<lambda> at 0x7fdbc1fb29d8>, {'location': [['VectorAssembler'], 'features'], 'ror': [['VectorAssembler'], 'features'], 'gender': [['VectorAssembler'], 'features'], 'name': [['VectorAssembler'], 'features'], 'price': [['VectorAssembler'], 'features']}) \n",
      "\n",
      "input cols: ['features'] output: scaledFeatures\n",
      "col: features\n",
      "first: ['location', 'ror', 'gender', 'name', 'price']\n",
      "Warning: Transformer MultilayerPerceptronClassifier_6252cda91cbf could not be parsed. If this is a model, this is expected.\n",
      "Warning: Transformer MultilayerPerceptronClassifier_6252cda91cbf could not be parsed. If this is a model, this is expected.\n",
      "input cols: None output: None\n",
      "Column- location location -> VectorAssembler -> StandardScaler -> scaledFeatures\n",
      "Column- ror ror -> VectorAssembler -> StandardScaler -> scaledFeatures\n",
      "Column- gender gender -> VectorAssembler -> StandardScaler -> scaledFeatures\n",
      "Column- name name -> VectorAssembler -> StandardScaler -> scaledFeatures\n",
      "Column- price price -> VectorAssembler -> StandardScaler -> scaledFeatures\n",
      "-------------------------------------------\n",
      "input cols: ['age', 'gender', 'height', 'weather_type', 'name'] output: features\n",
      "col: age\n",
      "first: None\n",
      "defaultdict(<function log_feature_transformations.<locals>.<lambda> at 0x7fdbc1f9e6a8>, {'age': [['VectorAssembler'], 'features']}) \n",
      "\n",
      "col: gender\n",
      "first: None\n",
      "defaultdict(<function log_feature_transformations.<locals>.<lambda> at 0x7fdbc1f9e6a8>, {'age': [['VectorAssembler'], 'features'], 'gender': [['VectorAssembler'], 'features']}) \n",
      "\n",
      "col: height\n",
      "first: None\n",
      "defaultdict(<function log_feature_transformations.<locals>.<lambda> at 0x7fdbc1f9e6a8>, {'age': [['VectorAssembler'], 'features'], 'gender': [['VectorAssembler'], 'features'], 'height': [['VectorAssembler'], 'features']}) \n",
      "\n",
      "col: weather_type\n",
      "first: None\n",
      "defaultdict(<function log_feature_transformations.<locals>.<lambda> at 0x7fdbc1f9e6a8>, {'age': [['VectorAssembler'], 'features'], 'gender': [['VectorAssembler'], 'features'], 'height': [['VectorAssembler'], 'features'], 'weather_type': [['VectorAssembler'], 'features']}) \n",
      "\n",
      "col: name\n",
      "first: None\n",
      "defaultdict(<function log_feature_transformations.<locals>.<lambda> at 0x7fdbc1f9e6a8>, {'age': [['VectorAssembler'], 'features'], 'gender': [['VectorAssembler'], 'features'], 'height': [['VectorAssembler'], 'features'], 'weather_type': [['VectorAssembler'], 'features'], 'name': [['VectorAssembler'], 'features']}) \n",
      "\n",
      "input cols: ['features'] output: scaledFeatures\n",
      "col: features\n",
      "first: ['age', 'gender', 'height', 'weather_type', 'name']\n",
      "Warning: Transformer DecisionTreeClassifier_7d8040305fde could not be parsed. If this is a model, this is expected.\n",
      "Warning: Transformer DecisionTreeClassifier_7d8040305fde could not be parsed. If this is a model, this is expected.\n",
      "input cols: None output: None\n",
      "Column- age age -> VectorAssembler -> StandardScaler -> scaledFeatures\n",
      "Column- gender gender -> VectorAssembler -> StandardScaler -> scaledFeatures\n",
      "Column- height height -> VectorAssembler -> StandardScaler -> scaledFeatures\n",
      "Column- weather_type weather_type -> VectorAssembler -> StandardScaler -> scaledFeatures\n",
      "Column- name name -> VectorAssembler -> StandardScaler -> scaledFeatures\n",
      "-------------------------------------------\n",
      "input cols: ['gender', 'height', 'location', 'weather_type', 'ror'] output: features\n",
      "col: gender\n",
      "first: None\n",
      "defaultdict(<function log_feature_transformations.<locals>.<lambda> at 0x7fdbc2504f28>, {'gender': [['VectorAssembler'], 'features']}) \n",
      "\n",
      "col: height\n",
      "first: None\n",
      "defaultdict(<function log_feature_transformations.<locals>.<lambda> at 0x7fdbc2504f28>, {'gender': [['VectorAssembler'], 'features'], 'height': [['VectorAssembler'], 'features']}) \n",
      "\n",
      "col: location\n",
      "first: None\n",
      "defaultdict(<function log_feature_transformations.<locals>.<lambda> at 0x7fdbc2504f28>, {'gender': [['VectorAssembler'], 'features'], 'height': [['VectorAssembler'], 'features'], 'location': [['VectorAssembler'], 'features']}) \n",
      "\n",
      "col: weather_type\n",
      "first: None\n",
      "defaultdict(<function log_feature_transformations.<locals>.<lambda> at 0x7fdbc2504f28>, {'gender': [['VectorAssembler'], 'features'], 'height': [['VectorAssembler'], 'features'], 'location': [['VectorAssembler'], 'features'], 'weather_type': [['VectorAssembler'], 'features']}) \n",
      "\n",
      "col: ror\n",
      "first: None\n",
      "defaultdict(<function log_feature_transformations.<locals>.<lambda> at 0x7fdbc2504f28>, {'gender': [['VectorAssembler'], 'features'], 'height': [['VectorAssembler'], 'features'], 'location': [['VectorAssembler'], 'features'], 'weather_type': [['VectorAssembler'], 'features'], 'ror': [['VectorAssembler'], 'features']}) \n",
      "\n",
      "input cols: ['features'] output: scaledFeatures\n",
      "col: features\n",
      "first: ['gender', 'height', 'location', 'weather_type', 'ror']\n",
      "Warning: Transformer DecisionTreeRegressor_9c9e614d177c could not be parsed. If this is a model, this is expected.\n",
      "Warning: Transformer DecisionTreeRegressor_9c9e614d177c could not be parsed. If this is a model, this is expected.\n",
      "input cols: None output: None\n",
      "Column- gender gender -> VectorAssembler -> StandardScaler -> scaledFeatures\n",
      "Column- height height -> VectorAssembler -> StandardScaler -> scaledFeatures\n",
      "Column- location location -> VectorAssembler -> StandardScaler -> scaledFeatures\n",
      "Column- weather_type weather_type -> VectorAssembler -> StandardScaler -> scaledFeatures\n",
      "Column- ror ror -> VectorAssembler -> StandardScaler -> scaledFeatures\n",
      "-------------------------------------------\n",
      "input cols: ['location', 'weather_type', 'age', 'ror', 'size'] output: features\n",
      "col: location\n",
      "first: None\n",
      "defaultdict(<function log_feature_transformations.<locals>.<lambda> at 0x7fdbc201b8c8>, {'location': [['VectorAssembler'], 'features']}) \n",
      "\n",
      "col: weather_type\n",
      "first: None\n",
      "defaultdict(<function log_feature_transformations.<locals>.<lambda> at 0x7fdbc201b8c8>, {'location': [['VectorAssembler'], 'features'], 'weather_type': [['VectorAssembler'], 'features']}) \n",
      "\n",
      "col: age\n",
      "first: None\n",
      "defaultdict(<function log_feature_transformations.<locals>.<lambda> at 0x7fdbc201b8c8>, {'location': [['VectorAssembler'], 'features'], 'weather_type': [['VectorAssembler'], 'features'], 'age': [['VectorAssembler'], 'features']}) \n",
      "\n",
      "col: ror\n",
      "first: None\n",
      "defaultdict(<function log_feature_transformations.<locals>.<lambda> at 0x7fdbc201b8c8>, {'location': [['VectorAssembler'], 'features'], 'weather_type': [['VectorAssembler'], 'features'], 'age': [['VectorAssembler'], 'features'], 'ror': [['VectorAssembler'], 'features']}) \n",
      "\n",
      "col: size\n",
      "first: None\n",
      "defaultdict(<function log_feature_transformations.<locals>.<lambda> at 0x7fdbc201b8c8>, {'location': [['VectorAssembler'], 'features'], 'weather_type': [['VectorAssembler'], 'features'], 'age': [['VectorAssembler'], 'features'], 'ror': [['VectorAssembler'], 'features'], 'size': [['VectorAssembler'], 'features']}) \n",
      "\n",
      "input cols: ['features'] output: scaledFeatures\n",
      "col: features\n",
      "first: ['location', 'weather_type', 'age', 'ror', 'size']\n",
      "Warning: Transformer KMeans_898554d51941 could not be parsed. If this is a model, this is expected.\n",
      "Warning: Transformer KMeans_898554d51941 could not be parsed. If this is a model, this is expected.\n",
      "input cols: None output: None\n",
      "Column- location location -> VectorAssembler -> StandardScaler -> scaledFeatures\n",
      "Column- weather_type weather_type -> VectorAssembler -> StandardScaler -> scaledFeatures\n",
      "Column- age age -> VectorAssembler -> StandardScaler -> scaledFeatures\n",
      "Column- ror ror -> VectorAssembler -> StandardScaler -> scaledFeatures\n",
      "Column- size size -> VectorAssembler -> StandardScaler -> scaledFeatures\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from splicemachine.ml.management import _get_cols,_readable_pipeline_stage,_get_stages\n",
    "from collections import defaultdict\n",
    "\n",
    "def _find_first_input_by_output(dictionary, value):\n",
    "        \"\"\"\n",
    "        Find the first input column for a given column\n",
    "        :param dictionary: dictionary to search\n",
    "        :param value: column\n",
    "        :return: None if not found, otherwise first column\n",
    "        \"\"\"\n",
    "        keys=[]\n",
    "        for key in dictionary:\n",
    "            if dictionary[key][1] == value:  # output column is always the last one\n",
    "                keys.append(key)\n",
    "        \n",
    "        return keys if len(keys)>0 else None\n",
    "\n",
    "\n",
    "def log_feature_transformations(unfit_pipeline):\n",
    "        \"\"\"\n",
    "        Log the preprocessing transformation sequence\n",
    "        for every feature in the UNFITTED Spark pipeline\n",
    "        :param unfit_pipeline: UNFITTED spark pipeline!!\n",
    "        \"\"\"\n",
    "        transformations = defaultdict(lambda: [[], None])  # transformations, outputColumn\n",
    "        \n",
    "\n",
    "        for stage in _get_stages(unfit_pipeline):\n",
    "            input_cols, output_col = _get_cols(stage, get_input=True), _get_cols(stage,\n",
    "                                                                               get_input=False)\n",
    "            print('input cols:',input_cols,'output:',output_col)\n",
    "            if input_cols and output_col:  # make sure it could parse transformer\n",
    "                for column in input_cols:\n",
    "                    print('col:',column)\n",
    "                    first_column_found = _find_first_input_by_output(transformations, column)\n",
    "                    print('first:',first_column_found)\n",
    "                    if first_column_found:  # column is not original\n",
    "                        for f in first_column_found:\n",
    "                            transformations[f][1] = output_col\n",
    "                            transformations[f][0].append(\n",
    "                                _readable_pipeline_stage(stage))\n",
    "                    else:\n",
    "                        transformations[column][1] = output_col\n",
    "                        transformations[column][0].append(_readable_pipeline_stage(stage))\n",
    "                        print(transformations,'\\n')\n",
    "\n",
    "        for column in transformations:\n",
    "            param_value = ' -> '.join([column] + transformations[column][0] +\n",
    "                                      [transformations[column][1]])\n",
    "            print('Column- ' + column, param_value)\n",
    "            \n",
    "for i in fitted_pipes:\n",
    "    log_feature_transformations(i)\n",
    "    print('-------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaledFeatures\n",
      "scaledFeatures\n",
      "scaledFeatures\n",
      "scaledFeatures\n",
      "scaledFeatures\n"
     ]
    }
   ],
   "source": [
    "for i in fitted_pipes:\n",
    "    print(i.getStages()[-1].getFeaturesCol())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list_artifacts() missing 1 required positional argument: 'run_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-264588c80ebf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_artifacts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list_artifacts() missing 1 required positional argument: 'run_id'"
     ]
    }
   ],
   "source": [
    "manager.list_artifacts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
